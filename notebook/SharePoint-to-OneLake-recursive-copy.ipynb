{"cells":[{"cell_type":"code","source":["## 0) Install dependency (once per session)\n","\n","%pip install msal --quiet\n","\n","\n","\n","## 1) Parameters (edit here)\n","# â”€â”€ App A: the app that this notebook uses to call Microsoft Graph (client-credential flow)\n","GRAPH_APP_CLIENT_ID       = \"<App A - Client ID>\"\n","GRAPH_APP_CLIENT_SECRET   = \"<App A - Client Secret>\"\n","GRAPH_TENANT_ID           = \"<Tenant (Directory) ID>\"\n","\n","# â”€â”€ SharePoint tenant & site (from your URL)\n","SP_TENANT_HOST            = \"MySharePoint.sharepoint.com\"\n","SP_SITE_PATH              = \"MySites123\"       # after /sites/\n","SP_TARGET_FOLDER_PATH     = \"01_MyFolders\"     # inside 'Documents' library; use \"A/B/C\" for deeper paths\n","\n","# â”€â”€ App B: the SECOND app you want to GRANT on this site (Sites.Selected target)\n","TARGET_APP_CLIENT_ID      = \"<App B - Client ID>\"\n","TARGET_APP_DISPLAY        = \"MySite123-SharePoint-Access\"\n","\n","# â”€â”€ If App A also needs to read/move files now, grant it too (helps avoid 403)\n","GRANT_CALLER_APP_TOO      = True\n","\n","# â”€â”€ Lakehouse Files destination\n","LAKEHOUSE_FILES_ROOT      = \"Files\"              # Fabric Lakehouse \"Files\" area (donâ€™t change)\n","LAKEHOUSE_SITE_FOLDER     = SP_SITE_PATH         # keep per-site subfolder organization\n","\n","\n","\n","## 2) Get a Graph token (client credentials with MSAL)\n","\n","from msal import ConfidentialClientApplication\n","\n","AUTHORITY = f\"https://login.microsoftonline.com/{GRAPH_TENANT_ID}\"\n","SCOPES    = [\"https://graph.microsoft.com/.default\"]\n","\n","print(\"ðŸ” Getting Microsoft Graph token (client credentials)â€¦\")\n","msal_app = ConfidentialClientApplication(\n","    client_id=GRAPH_APP_CLIENT_ID,\n","    authority=AUTHORITY,\n","    client_credential=GRAPH_APP_CLIENT_SECRET\n",")\n","token_result = msal_app.acquire_token_for_client(SCOPES)\n","if \"access_token\" not in token_result:\n","    raise RuntimeError(f\"Failed to get token: {token_result}\")\n","access_token = token_result[\"access_token\"]\n","print(\"âœ… Token acquired.\")\n","\n","\n","\n","## 3) Resolve siteId and prepare headers\n","\n","import requests\n","\n","headers = {\n","    \"Authorization\": f\"Bearer {access_token}\",\n","    \"Accept\": \"application/json\"\n","}\n","\n","print(f\"ðŸ”Ž Resolving siteId for https://{SP_TENANT_HOST}/sites/{SP_SITE_PATH} â€¦\")\n","site_url = f\"https://graph.microsoft.com/v1.0/sites/{SP_TENANT_HOST}:/sites/{SP_SITE_PATH}\"\n","site_res = requests.get(site_url, headers=headers)\n","site_res.raise_for_status()\n","site_id = site_res.json()[\"id\"]\n","print(\"âœ… siteId:\", site_id)\n","\n","\n","\n","## 4) Ensure Sites.Selected grant on the site\n","# This cell:\n","# 1) Checks existing app grants on the site\n","# 2) Grants \"write\" to App B (TARGET_APP_ID) if missing\n","# 3) (Optional) Grants \"write\" to App A (caller) if GRANT_CALLER_APP_TOO=True\n","\n","# ðŸ”Ž Helper: resolve app display name from Graph by appId (with safe fallback).\n","# Requires Directory.Read.All or Application.Read.All to succeed; otherwise we use the provided default_name.\n","APP_NAME_CACHE = {}\n","\n","def resolve_app_name(app_client_id: str, default_name: str) -> str:\n","    if app_client_id in APP_NAME_CACHE:\n","        return APP_NAME_CACHE[app_client_id]\n","\n","    try:\n","        # Try Enterprise App (service principal)\n","        sp_url = f\"https://graph.microsoft.com/v1.0/servicePrincipals?$filter=appId eq '{app_client_id}'&$select=displayName,appId\"\n","        sp_res = requests.get(sp_url, headers=headers)\n","        if sp_res.status_code == 200:\n","            vals = sp_res.json().get(\"value\", [])\n","            if vals:\n","                name = vals[0].get(\"displayName\") or default_name\n","                APP_NAME_CACHE[app_client_id] = name\n","                return name\n","        # Try App Registration (application)\n","        app_url = f\"https://graph.microsoft.com/v1.0/applications?$filter=appId eq '{app_client_id}'&$select=displayName,appId\"\n","        app_res = requests.get(app_url, headers=headers)\n","        if app_res.status_code == 200:\n","            vals = app_res.json().get(\"value\", [])\n","            if vals:\n","                name = vals[0].get(\"displayName\") or default_name\n","                APP_NAME_CACHE[app_client_id] = name\n","                return name\n","    except Exception:\n","        pass  # fall back\n","\n","    APP_NAME_CACHE[app_client_id] = default_name\n","    return default_name\n","\n","\n","def ensure_app_write_grant(site_id: str, app_client_id: str, display_name_hint: str):\n","    \"\"\"\n","    Ensure the given application (by Client ID) has 'write' on this site via Sites.Selected.\n","    Prints both appId and a friendly app name (resolved via Graph when possible).\n","    \"\"\"\n","    # Resolve a readable app name upfront (best effort)\n","    resolved_name = resolve_app_name(app_client_id, display_name_hint)\n","\n","    grant_url = f\"https://graph.microsoft.com/v1.0/sites/{site_id}/permissions\"\n","    res = requests.get(grant_url, headers=headers)\n","    res.raise_for_status()\n","\n","    already = False\n","    for perm in res.json().get(\"value\", []):\n","        for g in perm.get(\"grantedToIdentitiesV2\", []):\n","            app_obj = g.get(\"application\", {}) or {}\n","            gid = app_obj.get(\"id\")\n","            gname = app_obj.get(\"displayName\") or resolved_name\n","            if gid == app_client_id:\n","                print(f\"â„¹ï¸ App already granted: {gname} ({gid}) | roles: {perm.get('roles')}\")\n","                already = True\n","\n","    if not already:\n","        print(f\"ðŸ›‚ Granting 'write' to: {resolved_name} ({app_client_id}) on this site â€¦\")\n","        payload = {\n","            \"roles\": [\"write\"],\n","            \"grantedToIdentities\": [\n","                {\"application\": {\"id\": app_client_id, \"displayName\": resolved_name}}\n","            ]\n","        }\n","        create_res = requests.post(grant_url, headers=headers, json=payload)\n","        if create_res.status_code != 201:\n","            raise RuntimeError(f\"Grant failed for {resolved_name} ({app_client_id}): \"\n","                               f\"{create_res.status_code} {create_res.text}\")\n","        print(f\"âœ… Grant created for: {resolved_name} ({app_client_id}).\")\n","\n","\n","# 4a) Grant App B (target app) as requested\n","ensure_app_write_grant(site_id, TARGET_APP_CLIENT_ID, TARGET_APP_DISPLAY)\n","\n","# 4b) Optionally also grant the calling app (App A) to avoid 403s during file operations in this notebook\n","if GRANT_CALLER_APP_TOO and GRAPH_APP_CLIENT_ID != TARGET_APP_CLIENT_ID:\n","    ensure_app_write_grant(site_id, GRAPH_APP_CLIENT_ID, \"Notebook-Caller-App\")\n","\n","\n","\n","## 5) Get the Documents drive and resolve your target folder\n","# SharePointâ€™s default library is displayed as â€œShared Documentsâ€ in the URL, but Graph exposes it as Documents.\n","# The code below finds the documents library, then resolves SP_TARGET_FOLDER_PATH under its root.\n","\n","# Find a document library drive (prefer exact name 'Documents', fallback to first documentLibrary)\n","drives_url = f\"https://graph.microsoft.com/v1.0/sites/{site_id}/drives?$select=id,name,driveType\"\n","drv_res = requests.get(drives_url, headers=headers)\n","drv_res.raise_for_status()\n","drives = drv_res.json().get(\"value\", [])\n","\n","documents_drive_id = None\n","# prefer 'Documents'\n","for d in drives:\n","    if d.get(\"driveType\") == \"documentLibrary\" and d.get(\"name\") == \"Documents\":\n","        documents_drive_id = d[\"id\"]\n","        break\n","# fallback\n","if not documents_drive_id:\n","    for d in drives:\n","        if d.get(\"driveType\") == \"documentLibrary\":\n","            documents_drive_id = d[\"id\"]\n","            print(f\"â„¹ï¸ Using document library: {d.get('name')}\")\n","            break\n","\n","if not documents_drive_id:\n","    raise RuntimeError(\"No SharePoint document library drive found on this site.\")\n","\n","print(\"âœ… Documents driveId:\", documents_drive_id)\n","\n","# Resolve the target folder item\n","from urllib.parse import quote\n","encoded_folder_path = quote(SP_TARGET_FOLDER_PATH.strip(\"/\"))\n","folder_probe_url = f\"https://graph.microsoft.com/v1.0/drives/{documents_drive_id}/root:/{encoded_folder_path}\"\n","folder_probe = requests.get(folder_probe_url, headers=headers)\n","if folder_probe.status_code != 200:\n","    raise RuntimeError(\n","        f\"Target folder not found at 'Documents/{SP_TARGET_FOLDER_PATH}'. \"\n","        f\"Create it or correct SP_TARGET_FOLDER_PATH. Details: {folder_probe.status_code} {folder_probe.text}\"\n","    )\n","target_folder_id = folder_probe.json()[\"id\"]\n","print(f\"âœ… Target folder resolved: Documents/{SP_TARGET_FOLDER_PATH}\")\n","print(\"   targetFolderId:\", target_folder_id)\n","\n","\n","\n","## 6) Recursively enumerate all files under the target folder\n","# This walks subfolders and collects every file item (id, downloadUrl, relative path).\n","\n","def list_children_paged(list_url: str):\n","    \"\"\"Yield children arrays across @odata.nextLink pages.\"\"\"\n","    while list_url:\n","        r = requests.get(list_url, headers=headers)\n","        r.raise_for_status()\n","        body = r.json()\n","        yield body.get(\"value\", [])\n","        list_url = body.get(\"@odata.nextLink\")\n","\n","def collect_files_recursive(drive_id: str, folder_id: str, base_rel_path: str = \"\"):\n","    \"\"\"\n","    Depth-first traversal of a folder.\n","    Returns a list of dicts: {id, name, rel_path, downloadUrl}\n","    rel_path is the path under SP_TARGET_FOLDER_PATH (for mirroring on Lakehouse).\n","    \"\"\"\n","    results = []\n","    children_url = f\"https://graph.microsoft.com/v1.0/drives/{drive_id}/items/{folder_id}/children\"\n","    for page in list_children_paged(children_url):\n","        for it in page:\n","            name = it.get(\"name\", \"\")\n","            if \"folder\" in it:\n","                # Recurse into subfolder\n","                sub_id = it[\"id\"]\n","                sub_rel = f\"{base_rel_path}/{name}\" if base_rel_path else name\n","                results.extend(collect_files_recursive(drive_id, sub_id, sub_rel))\n","            elif \"file\" in it:\n","                results.append({\n","                    \"id\": it[\"id\"],\n","                    \"name\": name,\n","                    \"rel_path\": base_rel_path,  # may be \"\" at top-level\n","                    \"downloadUrl\": it.get(\"@microsoft.graph.downloadUrl\")\n","                })\n","    return results\n","\n","print(f\"ðŸ“‚ Scanning recursively under Documents/{SP_TARGET_FOLDER_PATH} â€¦\")\n","all_files = collect_files_recursive(documents_drive_id, target_folder_id, \"\")\n","print(f\"âœ… Found {len(all_files)} file(s) in Documents/{SP_TARGET_FOLDER_PATH} (recursive).\")\n","for preview in all_files[:10]:\n","    rel = f\"{SP_TARGET_FOLDER_PATH}/{preview['rel_path']}/{preview['name']}\".replace(\"//\",\"/\")\n","    print(\" â€¢\", rel)\n","\n","\n","\n","## 7) Copy each file to Lakehouse Files (preserve subfolder structure)\n","# Use the base64 strategy mssparkutils.fs.put() writes text.\n","# Each print includes a comment-style mapping line showing the exact SharePoint â†’ Lakehouse paths.\n","\n","import os, base64\n","from notebookutils import mssparkutils\n","\n","def lakehouse_dest_path(site_folder: str, rel_path: str, filename: str) -> str:\n","    # Mirror Documents/<SP_TARGET_FOLDER_PATH>/<rel_path>/<filename> under Files/<site>/<SP_TARGET_FOLDER_PATH>/<rel_path>/\n","    pieces = [LAKEHOUSE_FILES_ROOT, site_folder]\n","    if SP_TARGET_FOLDER_PATH:\n","        pieces.append(SP_TARGET_FOLDER_PATH.strip(\"/\"))\n","    if rel_path:\n","        pieces.append(rel_path.strip(\"/\"))\n","    pieces.append(filename)\n","    # Join with \"/\" to form OneLake-style path\n","    return \"/\".join(pieces).replace(\"//\", \"/\")\n","\n","def ensure_parent_dirs(full_path: str):\n","    # Make sure parent directories exist in Lakehouse Files\n","    parent = \"/\".join(full_path.split(\"/\")[:-1])\n","    if parent and not mssparkutils.fs.exists(parent):\n","        mssparkutils.fs.mkdirs(parent)\n","\n","def put_base64(path_in_lakehouse: str, raw_bytes: bytes):\n","    # Encode to base64 because fs.put writes text\n","    b64_text = base64.b64encode(raw_bytes).decode(\"utf-8\")\n","    mssparkutils.fs.put(path_in_lakehouse, b64_text, overwrite=True)\n","\n","copied = 0\n","for f in all_files:\n","    if not f.get(\"downloadUrl\"):\n","        print(f\"âš ï¸ Skipping (no downloadUrl): {f['name']}\")\n","        continue\n","\n","    # Compose readable SharePoint relative path for logging\n","    sp_rel = f\"Documents/{SP_TARGET_FOLDER_PATH}/{f['rel_path']}/{f['name']}\".replace(\"//\",\"/\")\n","\n","    # Download file content\n","    dl = requests.get(f[\"downloadUrl\"])\n","    if dl.status_code != 200:\n","        print(f\"âŒ Download failed: {sp_rel} (HTTP {dl.status_code})\")\n","        continue\n","\n","    # Compute Lakehouse path mirroring the SharePoint structure\n","    dest_path = lakehouse_dest_path(LAKEHOUSE_SITE_FOLDER, f[\"rel_path\"], f[\"name\"])\n","    ensure_parent_dirs(dest_path)\n","\n","    # â€œCommentâ€ line showing the exact mapping\n","    print(f\"# COPY: SP '{sp_rel}'  ->  Lakehouse '{dest_path}'\")\n","    put_base64(dest_path, dl.content)\n","\n","    print(f\"âœ… Copied: {f['name']}\")\n","    copied += 1\n","\n","print(f\"ðŸŽ‰ Completed. {copied} file(s) copied to Lakehouse.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ecc26c27-d977-4437-b3ea-85f5523d58b6"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"049b2e64-bc4e-4000-a920-564ef2f86953","known_lakehouses":[{"id":"049b2e64-bc4e-4000-a920-564ef2f86953"}],"default_lakehouse_name":"DWH_Lakehouse","default_lakehouse_workspace_id":"be8eade3-faab-4b06-8ba8-9ad3273e2327"}}},"nbformat":4,"nbformat_minor":5}